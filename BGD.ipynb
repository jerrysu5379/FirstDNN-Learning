{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:31.698016Z",
     "start_time": "2023-10-08T06:05:30.364173Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('svg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:31.701477Z",
     "start_time": "2023-10-08T06:05:31.698571Z"
    }
   },
   "id": "2832db1c9e17ce3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = 'mps'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:31.701884Z",
     "start_time": "2023-10-08T06:05:31.700373Z"
    }
   },
   "id": "a182df132bc3e32a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([759, 9])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Data.xlsx', index_col=0)\n",
    "arr = df.values\n",
    "arr = arr.astype(np.float32)\n",
    "#ts = torch.tensor(arr)\n",
    "ts = torch.from_numpy(arr)\n",
    "ts = ts.to(device)\n",
    "ts.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:31.871100Z",
     "start_time": "2023-10-08T06:05:31.702607Z"
    }
   },
   "id": "1362fc4c32fb41e6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([531, 9]), torch.Size([228, 9]))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(ts) * 0.7)\n",
    "test_size = len(ts) - train_size\n",
    "ts = ts[torch.randperm(ts.size(0)), :]\n",
    "train_Data = ts[:train_size, :]\n",
    "test_Data = ts[train_size:, :]\n",
    "train_Data.shape, test_Data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:31.884987Z",
     "start_time": "2023-10-08T06:05:31.871371Z"
    }
   },
   "id": "8f96845c1179ad3f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(8, 32), nn.Sigmoid(),\n",
    "            nn.Linear(32, 8), nn.Sigmoid(),\n",
    "            nn.Linear(8, 4), nn.Sigmoid(),\n",
    "            nn.Linear(4, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:31.887995Z",
     "start_time": "2023-10-08T06:05:31.884629Z"
    }
   },
   "id": "bd6c5f4fcf6e17cc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "DNN(\n  (net): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): Sigmoid()\n    (2): Linear(in_features=32, out_features=8, bias=True)\n    (3): Sigmoid()\n    (4): Linear(in_features=8, out_features=4, bias=True)\n    (5): Sigmoid()\n    (6): Linear(in_features=4, out_features=1, bias=True)\n    (7): Sigmoid()\n  )\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN().to(device)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:31.909798Z",
     "start_time": "2023-10-08T06:05:31.887399Z"
    }
   },
   "id": "c382591dcea80a23"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss(reduction='mean')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:31.914846Z",
     "start_time": "2023-10-08T06:05:31.894604Z"
    }
   },
   "id": "9d85898a0c5c9b47"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:32.213362Z",
     "start_time": "2023-10-08T06:05:31.896257Z"
    }
   },
   "id": "f39d46b6a7ed88c5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     12\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 13\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     15\u001B[0m Fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[1;32m     16\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[38;5;28mrange\u001B[39m(epochs), losses)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    368\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    369\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    370\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    371\u001B[0m             )\n\u001B[0;32m--> 373\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/optim/adam.py:163\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    152\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    155\u001B[0m         group,\n\u001B[1;32m    156\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    161\u001B[0m         state_steps)\n\u001B[0;32m--> 163\u001B[0m     adam(\n\u001B[1;32m    164\u001B[0m         params_with_grad,\n\u001B[1;32m    165\u001B[0m         grads,\n\u001B[1;32m    166\u001B[0m         exp_avgs,\n\u001B[1;32m    167\u001B[0m         exp_avg_sqs,\n\u001B[1;32m    168\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    169\u001B[0m         state_steps,\n\u001B[1;32m    170\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mamsgrad\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    171\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    172\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    173\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    174\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    175\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    176\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    177\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    178\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    179\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    180\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    181\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    182\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    183\u001B[0m     )\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/optim/adam.py:311\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    309\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 311\u001B[0m func(params,\n\u001B[1;32m    312\u001B[0m      grads,\n\u001B[1;32m    313\u001B[0m      exp_avgs,\n\u001B[1;32m    314\u001B[0m      exp_avg_sqs,\n\u001B[1;32m    315\u001B[0m      max_exp_avg_sqs,\n\u001B[1;32m    316\u001B[0m      state_steps,\n\u001B[1;32m    317\u001B[0m      amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[1;32m    318\u001B[0m      beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    319\u001B[0m      beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    320\u001B[0m      lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[1;32m    321\u001B[0m      weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[1;32m    322\u001B[0m      eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[1;32m    323\u001B[0m      maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[1;32m    324\u001B[0m      capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[1;32m    325\u001B[0m      differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[1;32m    326\u001B[0m      grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[1;32m    327\u001B[0m      found_inf\u001B[38;5;241m=\u001B[39mfound_inf)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/optim/adam.py:432\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    430\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    431\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 432\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    434\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[1;32m    436\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "losses = []\n",
    "\n",
    "X = train_Data[:, :-1]\n",
    "y = train_Data[:, -1].reshape((-1, 1))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    Pred = model(X)\n",
    "    loss = loss_fn(Pred, y)\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "   \n",
    "Fig = plt.figure()\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:50.845947Z",
     "start_time": "2023-10-08T06:05:32.215057Z"
    }
   },
   "id": "7331367a3753033c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = test_Data[:, :-1]\n",
    "Y = test_Data[:, -1].reshape((-1, 1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    Pred = model(X)\n",
    "    Pred[Pred >= 0.5] = 1\n",
    "    Pred[Pred < 0.5] = 0\n",
    "    correct = torch.sum((Pred == y).all(1))\n",
    "    total = Y.size(0)\n",
    "    print('Accuracy: {}%'.format(100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:50.846529Z",
     "start_time": "2023-10-08T06:05:50.846453Z"
    }
   },
   "id": "456cf74fba9e8a9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T06:05:50.846990Z",
     "start_time": "2023-10-08T06:05:50.846928Z"
    }
   },
   "id": "bef771b997687f6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
